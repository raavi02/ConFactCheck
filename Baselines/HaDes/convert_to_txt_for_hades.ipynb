{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Import all Necessary libraries. You can refer to https://github.com/microsoft/HaDes\n",
    "#### 2. Use the input pkl file with the specified format and continue with the notebook below for the formatted txt file generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"/custom/path/to/qwen_webq.pkl\", 'rb') as f:\n",
    "#Example input file which has a list-based format of -> [['Q1','A1'],['Q2','A2'],.......,['Qn','An']] which is loaded and further processed in the HaDes-specific format.\n",
    "#Qi in each sample of the input is the Question of the webq dataset in the case of \"qwen_webq.pkl\" and Ai is the original generated LLM answer for each Qi.\n",
    "    orig_ques_answers = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from tqdm import tqdm\n",
    "nlp_sent = spacy.load(\"en_core_web_sm\")\n",
    "answers = []\n",
    "def extract_first_sentence(orig_answer):\n",
    "    doc = nlp_sent(orig_answer)\n",
    "    sentences = [sent.text for sent in doc.sents]\n",
    "    return sentences[0]\n",
    "for question, answer in tqdm(orig_ques_answers):\n",
    "    answers.append(extract_first_sentence(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza\n",
    "stanza.download('en')     \n",
    "nlp_ner = stanza.Pipeline(lang='en', processors='tokenize,ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_subset_indices(orig, subset):\n",
    "    orig = orig.replace(\",\", \"\").replace(\".\", \"\")\n",
    "    orig_list = orig.split()\n",
    "    len_orig = len(orig_list)\n",
    "    len_sub = len(subset)\n",
    "    for i in range(len_orig - len_sub + 1):\n",
    "        if orig_list[i:i + len_sub] == subset:\n",
    "            return list(range(i , i + len_sub ))\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = [answer for question, answer in orig_ques_answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"/custom/path/to/golden_webq_judge_qwen.pkl\", 'rb') as f:\n",
    "#This pkl file contains the golden 0/1 labels for hallucination.\n",
    "    golden_hallucination = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json_format = []\n",
    "for answer, elt in tqdm(zip(answers,golden_hallucination)):\n",
    "    ner_sent = nlp_ner(answer)\n",
    "    output_list = [ent.text.replace(\",\", \"\").replace(\".\", \"\") for sent in ner_sent.sentences for ent in sent.ents]\n",
    "    replaced_ids = []\n",
    "    for subset in output_list:\n",
    "        replaced_ids += find_subset_indices(answer, subset.split())\n",
    "    json_format.append(json.dumps({\"replaced\": answer, \"replaced_ids\": replaced_ids[:2], \"hallucination\": elt}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/custom/path/to/qwen_webq_hades.txt', 'w') as file:\n",
    "    # Iterate over data and write each instance to the file\n",
    "    for instance in json_format:\n",
    "        file.write(instance + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "with open('/custom/path/to/qwen_webq_hades.txt', 'r+') as file:\n",
    "    for line in file:\n",
    "        json_format1 = json.loads(line.strip())\n",
    "        # print(json_format1['replaced_ids'])\n",
    "        if len(json_format1['replaced_ids']) == 1:\n",
    "            json_format1['replaced_ids'].append(json_format1['replaced_ids'][0])\n",
    "        if len(json_format1['replaced_ids']) == 0:\n",
    "            lst = [0,0]\n",
    "            json_format1['replaced_ids'] = lst\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Function to modify the replaced_ids\n",
    "def modify_replaced_ids(data):\n",
    "    for sample in data:\n",
    "        replaced_ids = sample['replaced_ids']\n",
    "        \n",
    "        if len(replaced_ids) == 0:\n",
    "            sample['replaced_ids'] = [0, 0]\n",
    "        elif len(replaced_ids) == 1:\n",
    "            sample['replaced_ids'].append(replaced_ids[0])\n",
    "\n",
    "# Read data from a text file\n",
    "with open('/custom/path/to/qwen_webq_hades.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "modified_data = []\n",
    "for line in lines:\n",
    "    try:\n",
    "        # Load the JSON object\n",
    "        sample = json.loads(line.strip())\n",
    "        modified_data.append(sample)\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Skipping invalid JSON line: {line.strip()}\")\n",
    "\n",
    "modify_replaced_ids(modified_data)\n",
    "with open('/custom/path/to/qwen_webq_hades1.txt', 'w') as file:   #Modified file.\n",
    "    for item in modified_data:\n",
    "        file.write(json.dumps(item) + '\\n')\n",
    "\n",
    "print(\"Data processing complete. Modified data saved to output.txt.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "with open('/custom/path/to/qwen_webq_hades1.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        json_format2 = json.loads(line.strip())\n",
    "        if len(json_format2['replaced_ids']) < 2:\n",
    "            count+=1\n",
    "print(count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "guard-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
